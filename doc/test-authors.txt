=======================
Manual for test authors
=======================

If you are writing tests for a Python project and you (rather wisely) want to
use testtools to do so, this is the manual for you.

We assume that you already know Python and that you know something about
automated testing already.


Introduction
============

testtools is a set of extensions to Python's standard unittest module.
Writing tests with testtools is very much like writing tests with standard
Python, or with Twisted's "trial", or nose, except a little bit easier and
more enjoyable.

Below, we'll try to give some examples of how to use testtools in its most
basic way, as well as a sort of feature-by-feature breakdown of the cool bits
that you could easily miss.


The basics
==========

Here's what a basic testtools unit tests look like::

  from testtools import TestCase
  from myproject import silly

  class TestSillySquare(TestCase):
      """Tests for silly square function."""

      def test_square(self):
          # 'square' takes a number and multiplies it by itself.
          result = silly.square(7)
          self.assertEqual(result, 49)

      def test_square_bad_input(self):
          # 'square' raises a TypeError if it's given bad input, say a
          # string.
          self.assertRaises(TypeError, silly.square, "orange")


Here you have a class that inherits from ``testtools.TestCase`` and bundles
together a bunch of related tests.  The tests themselves are methods on that
class that begin with 'test_'.

Running your tests
------------------

You can run these tests in many ways.  testtools provides a very basic
mechanism for doing so::

  $ python -m testtools.run exampletest
  Tests running...
  Ran 2 tests in 0.000s

  OK

where 'exampletest' is a module or package that contains unit tests.

As your testing needs grow and evolve, you will probably want to use a more
sophisticated test runner.  There are many of these for Python, and almost all
of them will happily run testtools tests.  In particular:

 * testrepository_
 * Trial_
 * nose_
 * unittest2_
 * zope.testrunner_ (aka zope.testing)

From now on, we'll assume that you know how to run your tests.


Assertions
==========

The core of automated testing is making assertions about the way things are,
and getting a nice, helpful, informative error message when things are not as
they ought to be.

All of the assertions that you can find in Python standard unittest_ can be
found in testtools (remember, testtools extends unittest).  testtools changes
the behaviour of some of those assertions slightly and adds some new
assertions that you will almost certainly find useful.


Improved assertRaises
---------------------

TestCase.assertRaises returns the caught exception.  This is useful for
asserting more things about the exception than just the type::

  def test_square_bad_input(self):
      # 'square' raises a TypeError if it's given bad input, say a
      # string.
      e = self.assertRaises(TypeError, silly.square, "orange")
      self.assertEqual("orange", e.bad_value)
      self.assertEqual("Cannot square 'orange', not a number.", str(e))

Note that this is incompatible with the assertRaises in unittest2 / Python2.7,
and that we have no immediate plans it to be so.


assertIn, assertNotIn
---------------------

These two assertions check whether a value is in a sequence and whether a
value is not in a sequence.  They are "assert" versions of the ``in`` and
``not in`` operators.  For example::

  def test_assert_in_example(self):
      self.assertIn('a', 'cat')
      self.assertNotIn('o', 'cat')
      self.assertIn(5, list_of_primes_under_ten)
      self.assertNotIn(12, list_of_primes_under_ten)


assertIs, assertIsNot
---------------------

These two assertions check whether values are identical to one another.  This
is sometimes useful when you want to test something stricter than mere
equality.  For example::

  def test_assert_is_example(self):
      foo = [None]
      foo_alias = foo
      bar = [None]
      self.assertIs(foo, foo_alias)
      self.assertIsNot(foo, bar)
      self.assertEqual(foo, bar) # They are equal, but not identical


assertIsInstance
----------------

As much as we love duck-typing and polymorphism, sometimes you need to check
whether or not a value is of a given type.  This method does that.

  def test_assert_is_instance_example(self):
      now = datetime.now()
      self.assertIsInstance(now, datetime)

Note that there is no 'assertIsNotInstance' in testtools currently.


Matchers
========

What are they?
--------------

The built-in assertion methods are very useful, they are the bread and butter
of writing tests.  However, soon enough you will probably want to write your
own assertions.  Perhaps there are domain specific things that you want to
check (e.g. assert that two widgets are aligned parallel to the flux grid), or
perhaps you want to check something that could almost but not quite be found
in some other standard library (e.g. assert that two paths point to the same
file).

When you are in such situations, you could either make a base class for your
project that inherits from ``testtools.TestCase`` and make sure that all of
your tests derive from that, *or* you could use testtools rather natty
``Matcher`` system.


Using Matchers
--------------

Here's a really basic example using stock matchers found in testtools::

  import testtools
  from testtools.matchers import Equals

  class TestSquare(TestCase):
      def test_square(self):
         result = square(7)
         self.assertThat(result, Equals(49))

The line ``self.assertThat(result, Equals(49))`` is equivalent to
``self.assertEqual(result, 49)``.  The difference is that ``assertThat`` is a
more general method that takes some kind of observed value (in this case,
``result``) and any matcher object (here, ``Equals(49)``).

The matcher object could be absolutely anything that implements the Matcher
protocol.  This means that you can make more complex matchers by combining
existing ones::

  def test_square_silly(self):
      result = square(7)
      self.assertThat(result, Not(Equals(50)))

Which is roughly equivalent to::

  def test_square_silly(self):
      result = square(7)
      self.assertNotEqual(result, 50)


Stock matchers
--------------

testtools comes with many matchers built in.  They can all be found in and
imported from the ``testtools.matchers`` module.

Equals
~~~~~~

Matches if two items are equal. For example::

  def test_equals_example(self):
      self.assertThat([42], Equals([42]))


Is
~~~

Matches if two items are identical.  For example::

  def test_is_example(self):
      foo = object()
      self.assertThat(foo, Is(foo))


raises
~~~~~~

Matches if a callable raises a particular type of exception.  For example::

  def test_raises_example(self):
      self.assertThat(lambda: 1/0, raises(ZeroDivisionError))

This is actually a convenience function that combines two other matchers:
Raises_ and MatchesException_.


DocTestMatches
~~~~~~~~~~~~~~

Matches a string as if it were the output of a doctest_ example.  Very useful
for making assertions about large chunks of text.  For example::

  import doctest

  def test_doctest_example(self):
      output = "Colorless green ideas"
      self.assertThat(
          output,
          DocTestMatches("Colorless ... ideas", doctest.ELLIPSIS))

We highly recommend using the following flags::
  doctest.ELLIPSIS | doctest.NORMALIZE_WHITESPACE | doctest.REPORT_NDIFF


LessThan
~~~~~~~~

Matches if the given thing is less than the thing in the matcher.  For
example::

  def test_less_than_example(self):
      self.assertThat(2, LessThan(3))


StartsWith, EndsWith
~~~~~~~~~~~~~~~~~~~~

These matchers check to see if a string starts with or ends with a particular
substring.  For example::

  def test_starts_and_ends_with_example(self):
      self.assertThat('underground', StartsWith('und'))
      self.assertThat('underground', EndsWith('und'))


MatchesException
~~~~~~~~~~~~~~~~

Matches an exc_info tuple if the exception is of the correct type.  For
example::

  def test_matches_exception_example(self):
      try:
          raise RuntimeError('foo')
      except RuntimeError:
          exc_info = sys.exc_info()
      self.assertThat(exc_info, MatchesException(RuntimeError))
      self.assertThat(exc_info, MatchesException(RuntimeError('bar'))

Most of the time, you will want to uses raises_ instead.


NotEquals
~~~~~~~~~

Matches if something is not equal to something else.  Note that this is subtly
different to ``Not(Equals(x))``.  ``NotEquals(x)`` will match if ``y != x``,
``Not(Equals(x))`` will match if ``not y == x``.

You only need to worry about this distinction if you are testing code that
relies on badly written overloaded equality operators.


Combining matchers
------------------

One great thing about matchers is that you can readily combine existing
matchers to get variations on their behaviour or to quickly build more complex
assertions.

Below are a few of the combining matchers that come with testtools.


Not
~~~

Negates another matcher.  For example::

  def test_not_example(self):
      self.assertThat([42], Not(Equals("potato")))
      self.assertThat([42], Not(Is([42])))

If you find yourself using ``Not`` frequently, you may wish to create a custom
matcher for it.  For example::

  IsNot = lambda x: Not(Is(x))

  def test_not_example_2(self):
      self.assertThat([42], IsNot([42]))


Annotate
~~~~~~~~

Used to add custom notes to a matcher.  For example::

  def test_annotate_example(self):
      result = 43
      self.assertThat(
          result, Annotate("Not the answer to the Question!", Equals(42))

Since the annotation is only ever displayed when there is a mismatch
(e.g. when ``result`` does not equal 42), it's a good idea to phrase the note
negatively, so that it describes what a mismatch actually means.

As with ``Not``_, you may wish to create a custom matcher that describes a
common operation.  For example::

  PoliticallyEquals = lambda x: Annotate("Death to the aristos!", Equals(x))

  def test_annotate_example_2(self):
      self.assertThat("orange", PoliticallyEquals("yellow"))


MatchesAll
~~~~~~~~~~

Combines many matchers to make a new matcher.  The new matcher will only match
things that match every single one of the component matchers.

It's much easier to understand in Python than in English::

  def test_matches_all_example(self):
      has_und_at_both_ends = MatchesAll(StartsWith("und"), EndsWith("und"))
      # This will succeed.
      self.assertThat("underground", has_und_at_both_ends)
      # This will fail.
      self.assertThat("found", has_und_at_both_ends)
      # So will this.
      self.assertThat("undead", has_und_at_both_ends)

At this point some people ask themselves, "why bother doing this at all? why
not just have two separate assertions?".  It's a good question.

The first reason is that when a ``MatchesAll` gets a mismatch, the error will
include information about all of the bits that mismatched.  When you have two
separate assertions, as below::

  def test_two_separate_assertions(self):
       self.assertThat("foo", StartsWith("und"))
       self.assertThat("foo", EndsWith("und"))

Then you get absolutely no information from the second assertion if the first
assertion fails.  Tests are largely there to help you debug code, so having
more information in error messages is a big help.

The second reason is that it is sometimes useful to give a name to a set of
matchers. ``has_und_at_both_ends`` is a bit contrived, of course, but it is
clear.


MatchesAny
~~~~~~~~~~

Like MatchesAll_, ``MatchesAny`` combines many matchers to make a new
matcher.  The difference is that the new matchers will match a thing if it
matches *any* of the component matchers.

For example::

  def test_matches_any_example(self):
      self.assertThat(42, MatchesAny(Equals(5), Not(Equals(6))))


Raises
~~~~~~

Takes whatever the callable raises as an exc_info tuple and matches it against
whatever matcher it was given.  For example, if you want to assert that a
callable raises an exception of a given type::

  def test_raises_example(self):
      self.assertThat(
          lambda: 1/0, Raises(MatchesException(ZeroDivisionError)))

Although note that this could also be written as::

  def test_raises_example_convenient(self):
      self.assertThat(lambda: 1/0, raises(ZeroDivisionError))


Writing your own matchers
-------------------------

Combining matchers is fun and can get you a very long way indeed, but
sometimes you will have to write your own.  Here's how.

You need to make two closely-linked objects: a ``Matcher`` and a
``Mismatch``.  The ``Matcher`` knows how to actually make the comparison, and
the ``Mismatch`` knows how describe a failure to match.

Here's an example matcher::

  class IsDivisibleBy(object):
      """Match if a number is divisible by another number."""
      def __init__(self, divider):
          self.divider = divider
      def __str__(self):
          return 'IsDivisibleBy(%s)' % (self.divider,)
      def match(self, actual):
          remainder = actual % self.divider
          if remainder != 0:
              return IsDivisibleByMismatch(actual, self.divider, remainder)
          else:
              return None

The matcher has a constructor that takes parameters that describe what you
actually *expect*, in this case a number that other numbers ought to be
divisible by.  It has a ``__str__`` method, the result of which is displayed
on failure by ``assertThat`` and a ``match`` method that does the actual
matching.

``match`` takes something to match against, here ``actual``, and decides
whether or not it matches.  If it does match, then ``match`` must return
``None``.  If it does *not* match, then ``match`` must return a ``Mismatch``
object. ``assertThat`` will call ``match`` and then fail the test if it
returns a non-None value.  For example::

  def test_is_divisible_by_example(self):
      # This succeeds, since IsDivisibleBy(5).match(10) returns None.
      self.assertThat(10, IsDivisbleBy(5))
      # This fails, since IsDivisibleBy(7).match(10) returns a mismatch.
      self.assertThat(10, IsDivisbleBy(7))

The mismatch is responsible for what sort of error message the failing test
generates.  Here's an example mismatch::

  class IsDivisibleByMismatch(object):
      def __init__(self, number, divider, remainder):
          self.number = number
          self.divider = divider
          self.remainder = remainder

      def describe(self):
          return "%s is not divisible by %s, %s remains" % (
              self.number, self.divider, self.remainder)

      def get_details(self):
          return {}

The mismatch takes information about the mismatch, and provides a ``describe``
method that assembles all of that into a nice error message for end users.
You can use the ``get_details`` method to provide extra, arbitrary data with
the mismatch (e.g. the contents of a log file).  Most of the time it's fine to
just return an empty dict.  You can read more about Details_ elsewhere in this
document.

Sometimes you don't need to create a custom mismatch class.  In particular, if
you don't care *when* the description is calculated, then you can just do that
in the Matcher itself like this::

  def match(self, actual):
      remainder = actual % self.divider
      if remainder != 0:
          return Mismatch(
              "%s is not divisible by %s, %s remains" % (
                  actual, self.divider, remainder))
      else:
          return None


Details
=======

XXX - add stuff here about addDetail and addOnException.  Refer to subunit and
to the test framework document that describes getDetails.

XXX - should we talk about content?


The rest
========

TestCase.addCleanup
-------------------

addCleanup is a robust way to arrange for a cleanup function to be called
before tearDown.  This is a powerful and simple alternative to putting cleanup
logic in a try/finally block or tearDown method.  e.g.::

    def test_foo(self):
        foo.lock()
        self.addCleanup(foo.unlock)
        ...

Cleanups can also report multiple errors, if appropriate by wrapping them in
a testtools.MultipleExceptions object::

    raise MultipleExceptions(exc_info1, exc_info2)


TestCase.patch
--------------

``patch`` is a convenient way to monkey-patch a Python object for the duration
of your test.  It's especially useful for testing legacy code.  e.g.::

    def test_foo(self):
        my_stream = StringIO()
        self.patch(sys, 'stderr', my_stream)
        run_some_code_that_prints_to_stderr()
        self.assertEqual('', my_stream.getvalue())

The call to ``patch`` above masks sys.stderr with 'my_stream' so that anything
printed to stderr will be captured in a StringIO variable that can be actually
tested. Once the test is done, the real sys.stderr is restored to its rightful
place.


TestCase.skipTest
-----------------

``skipTest`` is a simple way to have a test stop running and be reported as a
skipped test, rather than a success/error/failure. This is an alternative to
convoluted logic during test loading, permitting later and more localized
decisions about the appropriateness of running a test. Many reasons exist to
skip a test - for instance when a dependency is missing, or if the test is
expensive and should not be run while on laptop battery power, or if the test
is testing an incomplete feature (this is sometimes called a TODO). Using this
feature when running your test suite with a TestResult object that is missing
the ``addSkip`` method will result in the ``addError`` method being invoked
instead. ``skipTest`` was previously known as ``skip`` but as Python 2.7 adds
``skipTest`` support, the ``skip`` name is now deprecated (but no warning
is emitted yet - some time in the future we may do so).

TestCase.useFixture
-------------------

``useFixture(fixture)`` calls setUp on the fixture, schedules a cleanup to
clean it up, and schedules a cleanup to attach all details held by the
fixture to the details dict of the test case. The fixture object should meet
the ``fixtures.Fixture`` protocol (version 0.3.4 or newer). This is useful
for moving code out of setUp and tearDown methods and into composable side
classes.


Creation methods
----------------

testtools.TestCase implements creation methods called ``getUniqueString`` and
``getUniqueInteger``.  See pages 419-423 of *xUnit Test Patterns* by Meszaros
for a detailed discussion of creation methods.


Test discovery
--------------

testtools includes a backported version of the Python 2.7 glue for using the
discover test discovery module. If you either have Python 2.7/3.1 or newer, or
install the 'discover' module, then you can invoke discovery::

    python -m testtools.run discover [path]

For more information see the Python 2.7 unittest documentation, or::

    python -m testtools.run --help


Twisted support
---------------

Support for running Twisted tests is very experimental right now.  You
shouldn't really do it.  However, if you are going to, here are some tips for
converting your Trial tests into testtools tests.

 * Use the AsynchronousDeferredRunTest runner
 * Make sure to upcall to setUp and tearDown
 * Don't use setUpClass or tearDownClass
 * Don't expect setting .todo, .timeout or .skip attributes to do anything
 * flushLoggedErrors is not there for you.  Sorry.
 * assertFailure is not there for you.  Even more sorry.


General helpers
---------------

Lots of the time we would like to conditionally import modules.  testtools
needs to do this itself, and graciously extends the ability to its users.

Instead of::

    try:
        from twisted.internet import defer
    except ImportError:
        defer = None

You can do::

    defer = try_import('twisted.internet.defer')


Instead of::

    try:
        from StringIO import StringIO
    except ImportError:
        from io import StringIO

You can do::

    StringIO = try_imports(['StringIO.StringIO', 'io.StringIO'])


.. _testrepository: https://launchpad.net/testrepository
.. _Trial: http://twistedmatrix.com/documents/current/core/howto/testing.html
.. _nose: http://somethingaboutorange.com/mrl/projects/nose/
.. _unittest2: http://pypi.python.org/pypi/unittest2
.. _zope.testrunner: http://pypi.python.org/pypi/zope.testrunner/
